{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from nerfstudio.utils.eval_utils import eval_setup\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from nerfstudio.viewer.viewer import Viewer\n",
    "from nerfstudio.configs.base_config import ViewerConfig\n",
    "\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-03-12_120409/config.yml\")#appearance embed stride 14\n",
    "\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-03-12_124947/config.yml\")#no appearance embed and patch stride 7\n",
    "config = Path(\"outputs/garfield_plushie/dig/2024-03-12_125949/config.yml\")#no appearance embed and patch stride 14\n",
    "\n",
    "\n",
    "# config = Path(\"outputs/boops_mug/dig/2024-03-12_131401/config.yml\")\n",
    "_,pipeline,_,_ = eval_setup(config)\n",
    "dino_loader = pipeline.datamanager.dino_dataloader\n",
    "if hasattr(pipeline,\"garfield_pipeline\"):\n",
    "    v = Viewer(ViewerConfig(default_composite_depth=False),config.parent,pipeline.datamanager.get_datapath(),pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import moviepy.editor as mpy\n",
    "video_path = Path(\"garfield_move.mp4\")\n",
    "# video_path = Path(\"boops_lift.MOV\")\n",
    "motion_clip = mpy.VideoFileClip(str(video_path))\n",
    "if motion_clip.rotation == 90:\n",
    "    motion_clip = motion_clip.resize(motion_clip.size[::-1])\n",
    "    motion_clip.rotation = 0\n",
    "#print length of video in seconds\n",
    "frame = motion_clip.get_frame(7.2)\n",
    "pil_image = ToTensor()(Image.fromarray(frame))\n",
    "\n",
    "# image_path = Path(\"/home/justin/nerfstudio/data/colorful_mugs_colmap/images/frame_00010.jpg\")\n",
    "# image_path = Path(\"/home/justin/nerfstudio/data/louvre_statue/images/frame_00170.png\")\n",
    "# pil_image = ToTensor()(Image.open(image_path))\n",
    "img_pca_feats = dino_loader.get_pca_feats(pil_image.unsqueeze(0)).cuda().squeeze()\n",
    "cam,data = pipeline.datamanager.next_train(0)\n",
    "outputs = pipeline.model.get_outputs_for_camera(cam)\n",
    "which_to_rgb_pca = torch.cat([outputs['dino'].view(-1,img_pca_feats.shape[-1]),img_pca_feats.view(-1,img_pca_feats.shape[-1])],dim=0)\n",
    "_,_,rgb_pca = torch.pca_lowrank(which_to_rgb_pca.view(-1,which_to_rgb_pca.shape[-1]), q=3, niter=30)\n",
    "from nerfstudio.utils.colormaps import apply_pca_colormap\n",
    "\n",
    "fig,axs = plt.subplots(1,4,figsize=(20,10))\n",
    "axs[0].imshow(pil_image.permute(1,2,0).cpu().numpy())\n",
    "axs[1].imshow(data[\"image\"].cpu().numpy())\n",
    "axs[2].imshow(apply_pca_colormap(img_pca_feats,rgb_pca).cpu().numpy())\n",
    "axs[3].imshow(apply_pca_colormap(outputs[\"dino\"],rgb_pca).cpu().numpy())\n",
    "click_coords = []\n",
    "def onclick(event):\n",
    "    # Check if the click was on one of the axes\n",
    "    for i, ax in enumerate(axs):\n",
    "        if event.inaxes == ax:\n",
    "            if i == 3:\n",
    "                click_coords.append((int(event.ydata),int(event.xdata)))\n",
    "            break\n",
    "fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from nerfstudio.utils.colormaps import apply_float_colormap\n",
    "def get_matches(feats1,feats2,feats1_coords):\n",
    "    matches,dist_maps = [],[]\n",
    "    for i,pc in enumerate(feats1_coords):\n",
    "        single_feat = feats1[pc[0],pc[1],:]\n",
    "        dists = (single_feat - feats2).norm(dim=-1,keepdim=True)\n",
    "        dist_maps.append(dists)\n",
    "        argmin = torch.argmin(dists).cpu().numpy()\n",
    "        argmin_coords = (argmin//dists.shape[1],argmin%dists.shape[1])\n",
    "        matches.append(argmin_coords)\n",
    "    return matches,dist_maps\n",
    "\n",
    "def plot_matches(img1, img2, coords1, coords2, distance_maps = []):\n",
    "    \"\"\"\n",
    "    Takes in the two images and returns a PIL of the matches\n",
    "    coords are specified in terms of percent of the (h,w) of each img1, img2\n",
    "    \"\"\"\n",
    "    img1 = img1.cpu().numpy()\n",
    "    img2 = img2.cpu().numpy()\n",
    "    h1,w1 = img1.shape[:2]\n",
    "    h2,w2 = img2.shape[:2]\n",
    "    #convert coords to pixel coords\n",
    "    coords1 = [(int(c[1]*w1),int(c[0]*h1)) for c in coords1]\n",
    "    coords2 = [(int(c[1]*w2),int(c[0]*h2)) for c in coords2]\n",
    "    #concatenate the images using PIL\n",
    "    img1 = Image.fromarray((img1*255).astype(np.uint8))\n",
    "    img2 = Image.fromarray((img2*255).astype(np.uint8))\n",
    "    W = w1 + w2 + w1*len(distance_maps)\n",
    "    new_img = Image.new('RGB',(W,max(h1,h2)))\n",
    "    new_img.paste(img1,(0,0))\n",
    "    new_img.paste(img2,(w1,0))\n",
    "    for i,d in enumerate(distance_maps):\n",
    "        max_val = max([d.max().item() for d in distance_maps])\n",
    "        d = apply_float_colormap(d/max_val).cpu().numpy()\n",
    "        d = (d*255).astype(np.uint8)\n",
    "        d = cv2.resize(d,(w1,h1))\n",
    "        d = Image.fromarray(d)\n",
    "        new_img.paste(d,(w1 + w2 + w1*i,0))\n",
    "    new_img = np.array(new_img)\n",
    "    #draw lines between the matches\n",
    "    for i,(c1,c2) in enumerate(zip(coords1,coords2)):\n",
    "        c2 = (c2[0]+w1,c2[1])\n",
    "        cv2.line(new_img,c1,c2,(255,0,0),2)\n",
    "        #draw a small x at each end of the line\n",
    "        cv2.drawMarker(new_img,c1,(0,255,0),markerType=cv2.MARKER_CROSS,markerSize=10,thickness=1)\n",
    "        cv2.drawMarker(new_img,c2,(0,255,0),markerType=cv2.MARKER_CROSS,markerSize=10,thickness=1)\n",
    "        #draw a small number next to the startpoint of the line\n",
    "        cv2.putText(new_img,str(i),c1,cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "    return new_img\n",
    "\n",
    "def visualize_matches(pix_coords, feats1, feats2,rgb1,rgb2,include_distance_maps = False):\n",
    "    matches,distance_maps = get_matches(feats1, feats2, pix_coords)\n",
    "    coords_norm1 = [((p[0]+0.5)/feats1.shape[0],(p[1]+0.5)/feats1.shape[1]) for p in pix_coords]\n",
    "    coords_norm2 = [((p[0]+0.5)/feats2.shape[0],(p[1]+0.5)/feats2.shape[1]) for p in matches]\n",
    "    return plot_matches(rgb1, rgb2, coords_norm1, coords_norm2, distance_maps if include_distance_maps else [])\n",
    "\n",
    "\n",
    "gif_frames = []\n",
    "pix_coords = click_coords + []\n",
    "t_start = 1\n",
    "t_end = 8\n",
    "fps = 10\n",
    "for t in np.linspace(t_start,t_end,(t_end-t_start)*fps):\n",
    "    frame = motion_clip.get_frame(t)\n",
    "    pil_image = ToTensor()(Image.fromarray(frame))\n",
    "    img_pca_feats = dino_loader.get_pca_feats(pil_image.unsqueeze(0)).cuda().squeeze()\n",
    "    img = visualize_matches(pix_coords, outputs[\"dino\"], img_pca_feats, outputs['rgb'], pil_image.permute(1,2,0))\n",
    "    gif_frames.append(img)\n",
    "#save with mediapy\n",
    "out_clip = mpy.ImageSequenceClip(gif_frames, fps=fps)\n",
    "out_clip.write_videofile(\"garfield_matches.mp4\", fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import ConnectionPatch\n",
    "pix_coords = [(10,30),(27,30)]\n",
    "pix_matches = []\n",
    "_,diff_axs = plt.subplots(2,len(pix_coords),figsize=(20,10))\n",
    "for i,pc in enumerate(pix_coords):\n",
    "    img_pca_feat = img_pca_feats[pc[0],pc[1],:]\n",
    "    distance_img = (outputs['dino'] - img_pca_feat).pow(2).sum(dim=-1).sqrt()[...,None]\n",
    "    img_distance = (img_pca_feats - img_pca_feat).pow(2).sum(dim=-1).sqrt()\n",
    "    diff_axs[0,i].imshow(distance_img.cpu().numpy().squeeze(),vmin = 10,vmax=30)\n",
    "    diff_axs[1,i].imshow(img_distance.cpu().numpy(),vmin = 10,vmax=30)\n",
    "    argmin = torch.argmin(distance_img).cpu().numpy()\n",
    "    argmin_coords = (argmin//distance_img.shape[1],argmin%distance_img.shape[1])\n",
    "    pix_matches.append(argmin_coords)\n",
    "fig,axs = plt.subplots(1,2,figsize=(20,10))\n",
    "#visualize the input click on the original image\n",
    "axs[0].imshow(apply_pca_colormap(img_pca_feats,rgb_pca).cpu().numpy())\n",
    "axs[1].imshow(apply_pca_colormap(outputs[\"dino\"],rgb_pca).cpu().numpy())\n",
    "for i in range(len(pix_matches)):\n",
    "    color = np.random.rand(3)\n",
    "    transFigure = fig.transFigure.inverted()\n",
    "    con = ConnectionPatch(xyA=(pix_coords[i][1],pix_coords[i][0]), xyB=(pix_matches[i][1],pix_matches[i][0]),\n",
    "                           coordsA=\"data\", coordsB=\"data\",\n",
    "                      axesA=axs[0], axesB=axs[1], color=color)\n",
    "    fig.add_artist(con)\n",
    "    axs[0].scatter(pix_coords[i][1],pix_coords[i][0],c=color,s=300)\n",
    "    axs[1].scatter(pix_matches[i][1],pix_matches[i][0],c=color,s=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
