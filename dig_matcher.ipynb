{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from nerfstudio.utils.eval_utils import eval_setup\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from nerfstudio.viewer.viewer import Viewer\n",
    "from nerfstudio.configs.base_config import ViewerConfig\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-02-27_144117/config.yml\")#pca 64\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-02-27_163355/config.yml\")#pca 128\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-02-27_164651/config.yml\")#v2 128 dim\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-02-27_170339/config.yml\")##v2 128 dim, 7stride\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-02-28_180544/config.yml\")#v2, 64 dim 7 stride\n",
    "#all above s model\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-02-29_133302/config.yml\")#v2, b model, 64 dim 7 stride\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-02-29_135125/config.yml\")#v2, b model, 64 dim 14 stride\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-02-29_142826/config.yml\")#v2, b model, 64 dim 14 stride, huber loss\n",
    "# config = Path(\"outputs/louvre_statue/dig/2024-02-29_144220/config.yml\")#v2, b model, 64 dim 14 stride, huber loss\n",
    "\n",
    "config = Path(\"outputs/garfield_plushie/dig/2024-03-01_120451/config.yml\")#with garfield\n",
    "_,pipeline,_,_ = eval_setup(config)\n",
    "dino_loader = pipeline.datamanager.dino_dataloader\n",
    "if hasattr(pipeline,\"garfield_pipeline\"):\n",
    "    v = Viewer(ViewerConfig(default_composite_depth=False),config.parent,pipeline.datamanager.get_datapath(),pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import moviepy.editor as mpy\n",
    "from plotly import graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode()\n",
    "video_path = Path(\"/home/justin/Downloads/garfield_move.mp4\")\n",
    "clip = mpy.VideoFileClip(str(video_path))\n",
    "#print length of video in seconds\n",
    "frame = clip.get_frame(6.5)\n",
    "pil_image = ToTensor()(Image.fromarray(frame))\n",
    "\n",
    "# image_path = Path(\"/home/justin/nerfstudio/data/colorful_mugs_colmap/images/frame_00010.jpg\")\n",
    "# image_path = Path(\"/home/justin/nerfstudio/data/louvre_statue/images/frame_00170.png\")\n",
    "# pil_image = ToTensor()(Image.open(image_path))\n",
    "img_pca_feats = dino_loader.get_pca_feats(pil_image.unsqueeze(0)).cuda().squeeze()\n",
    "cam,data = pipeline.datamanager.next_train(0)\n",
    "outputs = pipeline.model.get_outputs_for_camera(cam)\n",
    "outputs['dino'][outputs['dino_alpha']<.9] = 0\n",
    "which_to_rgb_pca = torch.cat([outputs['dino'].view(-1,img_pca_feats.shape[-1]),img_pca_feats.view(-1,img_pca_feats.shape[-1])],dim=0)\n",
    "# which_to_rgb_pca = outputs['dino'].view(-1,img_pca_feats.shape[-1])\n",
    "_,_,rgb_pca = torch.pca_lowrank(which_to_rgb_pca.view(-1,which_to_rgb_pca.shape[-1]), q=3, niter=30)\n",
    "from nerfstudio.utils.colormaps import apply_pca_colormap\n",
    "_,axs = plt.subplots(1,4,figsize=(20,10))\n",
    "axs[0].imshow(pil_image.permute(1,2,0).cpu().numpy())\n",
    "axs[1].imshow(data[\"image\"].cpu().numpy())\n",
    "axs[2].imshow(apply_pca_colormap(img_pca_feats,rgb_pca).cpu().numpy())\n",
    "axs[3].imshow(apply_pca_colormap(outputs[\"dino\"],rgb_pca).cpu().numpy())\n",
    "plt.show()\n",
    "#same thing but with plotly\n",
    "# fig = make_subplots(rows=1, cols=4)\n",
    "# # Add images to each subplot\n",
    "# fig.add_trace(go.Image(z=pil_image.permute(1, 2, 0).cpu().numpy()*255), row=1, col=1)\n",
    "# fig.add_trace(go.Image(z=data[\"image\"].cpu().numpy()*255), row=1, col=2)\n",
    "# fig.add_trace(go.Image(z=apply_pca_colormap(img_pca_feats, rgb_pca).cpu().numpy()*255), row=1, col=3)\n",
    "# fig.add_trace(go.Image(z=apply_pca_colormap(outputs[\"dino\"], rgb_pca).cpu().numpy()*255), row=1, col=4)\n",
    "# fig.update_layout(width=1500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import ConnectionPatch\n",
    "pix_coords = [(10,30),(26,37)]\n",
    "pix_matches = []\n",
    "_,diff_axs = plt.subplots(2,len(pix_coords),figsize=(20,10))\n",
    "for i,pc in enumerate(pix_coords):\n",
    "    img_pca_feat = img_pca_feats[pc[0],pc[1],:]\n",
    "    distance_img = (outputs['dino'] - img_pca_feat).pow(2).sum(dim=-1).sqrt()[...,None]\n",
    "    img_distance = (img_pca_feats - img_pca_feat).pow(2).sum(dim=-1).sqrt()\n",
    "    # print(img_distance.max().item(),img_distance.min().item())\n",
    "    # print(distance_img.max().item(),distance_img.min().item())\n",
    "    diff_axs[0,i].imshow(distance_img.cpu().numpy().squeeze(),vmin = 10,vmax=30)\n",
    "    diff_axs[1,i].imshow(img_distance.cpu().numpy(),vmin = 10,vmax=30)\n",
    "    argmin = torch.argmin(distance_img).cpu().numpy()\n",
    "    argmin_coords = (argmin//distance_img.shape[1],argmin%distance_img.shape[1])\n",
    "    pix_matches.append(argmin_coords)\n",
    "fig,axs = plt.subplots(1,2,figsize=(20,10))\n",
    "#visualize the input click on the original image\n",
    "axs[0].imshow(apply_pca_colormap(img_pca_feats,rgb_pca).cpu().numpy())\n",
    "axs[1].imshow(apply_pca_colormap(outputs[\"dino\"],rgb_pca).cpu().numpy())\n",
    "for i in range(len(pix_matches)):\n",
    "    color = np.random.rand(3)\n",
    "    transFigure = fig.transFigure.inverted()\n",
    "    con = ConnectionPatch(xyA=(pix_coords[i][1],pix_coords[i][0]), xyB=(pix_matches[i][1],pix_matches[i][0]),\n",
    "                           coordsA=\"data\", coordsB=\"data\",\n",
    "                      axesA=axs[0], axesB=axs[1], color=color)\n",
    "    fig.add_artist(con)\n",
    "    axs[0].scatter(pix_coords[i][1],pix_coords[i][0],c=color,s=300)\n",
    "    axs[1].scatter(pix_matches[i][1],pix_matches[i][0],c=color,s=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
