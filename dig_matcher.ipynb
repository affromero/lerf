{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell loads the model from the config file and initializes the viewer\n",
    "'''\n",
    "%matplotlib widget\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from nerfstudio.utils.eval_utils import eval_setup\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from nerfstudio.viewer.viewer import Viewer\n",
    "from nerfstudio.configs.base_config import ViewerConfig\n",
    "\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-03-12_153919/config.yml\")#denoised with patch stride 7 and enable_pe\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-03-12_155712/config.yml\")#denoised with stride 7 and no enable_pe\n",
    "# config = Path(\"outputs/garfield_plushie/dig/2024-03-12_160428/config.yml\")#non-denoised patch size 7\n",
    "\n",
    "# config = Path(\"outputs/nerfgun/dig/2024-03-12_162138/config.yml\")#denoised nerfgun, patch stride 7\n",
    "# config = Path(\"outputs/nerfgun/dig/2024-03-12_163729/config.yml\") #denoised nerfgun, patch stride 14\n",
    "\n",
    "# config = Path(\"outputs/nerfgun2/dig/2024-03-12_165027/config.yml\")#nerfgun2 stride 14, denoised\n",
    "# config = Path(\"outputs/nerfgun2/dig/2024-03-12_171730/config.yml\")#stride 7\n",
    "config = Path(\"outputs/nerfgun2/dig/2024-03-13_151932/config.yml\")#stride 7, with garfield\n",
    "\n",
    "# config = Path(\"outputs/boops_mug/dig/2024-03-13_141111/config.yml\")#denoise stride 7\n",
    "_,pipeline,_,_ = eval_setup(config)\n",
    "pipeline.eval()\n",
    "dino_loader = pipeline.datamanager.dino_dataloader\n",
    "v = Viewer(ViewerConfig(default_composite_depth=False),config.parent,pipeline.datamanager.get_datapath(),pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell loads the video, picks a random train cam, and shows the pca of the video frame and the random train view.\n",
    "you can then click on the pca feats in the rendered view to pick keypoints to match in the video\n",
    "'''\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import cv2\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "video_path = Path(\"garfield_move.mp4\")\n",
    "assert video_path.exists()\n",
    "motion_clip = cv2.VideoCapture(str(video_path.absolute()))\n",
    "def get_vid_frame(cap,timestamp):\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Calculate the frame number based on the timestamp and fps\n",
    "    frame_number = min(int(timestamp * fps),int(cap.get(cv2.CAP_PROP_FRAME_COUNT)-1))\n",
    "    \n",
    "    # Set the video position to the calculated frame number\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "    \n",
    "    # Read the frame\n",
    "    success, frame = cap.read()\n",
    "    # convert BGR to RGB\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    return frame\n",
    "frame = get_vid_frame(motion_clip,7.2)\n",
    "pil_image = ToTensor()(Image.fromarray(frame))\n",
    "\n",
    "# image_path = Path(\"/home/justin/nerfstudio/data/colorful_mugs_colmap/images/frame_00010.jpg\")\n",
    "# image_path = Path(\"/home/justin/nerfstudio/data/louvre_statue/images/frame_00170.png\")\n",
    "# pil_image = ToTensor()(Image.open(image_path))\n",
    "img_pca_feats = dino_loader.get_pca_feats(pil_image.unsqueeze(0)).cuda().squeeze()\n",
    "\n",
    "cam,data = pipeline.datamanager.next_train(0)\n",
    "outputs = pipeline.model.get_outputs_for_camera(cam)\n",
    "which_to_rgb_pca = torch.cat([outputs['dino'].view(-1,img_pca_feats.shape[-1]),img_pca_feats.view(-1,img_pca_feats.shape[-1])],dim=0)\n",
    "_,_,rgb_pca = torch.pca_lowrank(which_to_rgb_pca.view(-1,which_to_rgb_pca.shape[-1]), q=3, niter=30)\n",
    "from nerfstudio.utils.colormaps import apply_pca_colormap\n",
    "\n",
    "fig,axs = plt.subplots(1,4,figsize=(20,5))\n",
    "axs[0].imshow(pil_image.permute(1,2,0).cpu().numpy())\n",
    "axs[1].imshow(data[\"image\"].cpu().numpy())\n",
    "axs[2].imshow(apply_pca_colormap(img_pca_feats,rgb_pca).cpu().numpy())\n",
    "axs[3].imshow(apply_pca_colormap(outputs[\"dino\"],rgb_pca).cpu().numpy())\n",
    "click_coords = []\n",
    "def onclick(event):\n",
    "    # Check if the click was on one of the axes\n",
    "    for i, ax in enumerate(axs):\n",
    "        if event.inaxes == ax:\n",
    "            if i == 3:\n",
    "                click_coords.append((int(event.ydata),int(event.xdata)))\n",
    "            break\n",
    "fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell defines some useful functions for finding matches in frames and visualizing them\n",
    "'''\n",
    "    \n",
    "from nerfstudio.utils.colormaps import apply_float_colormap\n",
    "def get_matches(feats1,feats2,feats1_coords):\n",
    "    matches,dist_maps = [],[]\n",
    "    for i,pc in enumerate(feats1_coords):\n",
    "        single_feat = feats1[pc[0],pc[1],:]\n",
    "        dists = (single_feat - feats2).norm(dim=-1,keepdim=True)\n",
    "        dist_maps.append(dists)\n",
    "        argmin = torch.argmin(dists).cpu().numpy()\n",
    "        argmin_coords = (argmin//dists.shape[1],argmin%dists.shape[1])\n",
    "        matches.append(argmin_coords)\n",
    "    return matches,dist_maps\n",
    "\n",
    "def plot_matches(img1, img2, coords1, coords2, distance_maps = []):\n",
    "    \"\"\"\n",
    "    Takes in the two images and returns a PIL of the matches\n",
    "    coords are specified in terms of percent of the (h,w) of each img1, img2\n",
    "    \"\"\"\n",
    "    img1 = img1.cpu().numpy()\n",
    "    img2 = img2.cpu().numpy()\n",
    "    h1,w1 = img1.shape[:2]\n",
    "    h2,w2 = img2.shape[:2]\n",
    "    #convert coords to pixel coords\n",
    "    coords1 = [(int(c[1]*w1),int(c[0]*h1)) for c in coords1]\n",
    "    coords2 = [(int(c[1]*w2),int(c[0]*h2)) for c in coords2]\n",
    "    #concatenate the images using PIL\n",
    "    img1 = Image.fromarray((img1*255).astype(np.uint8))\n",
    "    img2 = Image.fromarray((img2*255).astype(np.uint8))\n",
    "    W = w1 + w2 + w1*len(distance_maps)\n",
    "    new_img = Image.new('RGB',(W,max(h1,h2)))\n",
    "    new_img.paste(img1,(0,0))\n",
    "    new_img.paste(img2,(w1,0))\n",
    "    for i,d in enumerate(distance_maps):\n",
    "        max_val = max([d.max().item() for d in distance_maps])\n",
    "        d = apply_float_colormap(d/max_val).cpu().numpy()\n",
    "        d = (d*255).astype(np.uint8)\n",
    "        d = cv2.resize(d,(w1,h1))\n",
    "        d = Image.fromarray(d)\n",
    "        new_img.paste(d,(w1 + w2 + w1*i,0))\n",
    "    new_img = np.array(new_img)\n",
    "    #draw lines between the matches\n",
    "    for i,(c1,c2) in enumerate(zip(coords1,coords2)):\n",
    "        c2 = (c2[0]+w1,c2[1])\n",
    "        cv2.line(new_img,c1,c2,(255,0,0),2)\n",
    "        #draw a small x at each end of the line\n",
    "        cv2.drawMarker(new_img,c1,(0,255,0),markerType=cv2.MARKER_CROSS,markerSize=10,thickness=1)\n",
    "        cv2.drawMarker(new_img,c2,(0,255,0),markerType=cv2.MARKER_CROSS,markerSize=10,thickness=1)\n",
    "        #draw a small number next to the startpoint of the line\n",
    "        cv2.putText(new_img,str(i),c1,cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),3)\n",
    "    return new_img\n",
    "\n",
    "def plot_distribution(img1, img2, coords1, distance_maps, cutoff = 3.0):\n",
    "    img1 = img1.cpu().numpy()\n",
    "    img2 = img2.cpu().numpy()\n",
    "    h1,w1 = img1.shape[:2]\n",
    "    h2,w2 = img2.shape[:2]\n",
    "    #convert coords to pixel coords\n",
    "    coords1 = [(int(c[1]*w1),int(c[0]*h1)) for c in coords1]\n",
    "    #concatenate the images using PIL\n",
    "    img1 = Image.fromarray((img1*255).astype(np.uint8))\n",
    "    img2 = Image.fromarray((img2*255).astype(np.uint8))\n",
    "    W = w1 + w2\n",
    "    new_img = Image.new('RGB',(W,max(h1,h2)))\n",
    "    new_img.paste(img1,(0,0))\n",
    "    new_img.paste(img2,(w1,0))\n",
    "    #generate unique colors for each distance map\n",
    "    colors = np.random.randint(0,255,(len(distance_maps),3))\n",
    "    for i,d in enumerate(distance_maps):\n",
    "        d = d.cpu().numpy()\n",
    "        alpha_img = np.zeros((h2,w2),dtype=np.uint8)\n",
    "        distribution_img = np.zeros((h2,w2,3),dtype=np.uint8)\n",
    "        upscaled_d = cv2.resize(d,(w2,h2))\n",
    "        alpha_img[upscaled_d<=cutoff] = upscaled_d[upscaled_d<=cutoff]*255/cutoff\n",
    "        distribution_img[upscaled_d<=cutoff] = colors[i]\n",
    "        #paste the distribution image onto new_img weighted by alpha\n",
    "        new_img.paste(Image.fromarray(distribution_img),(w1,0),Image.fromarray(alpha_img,mode='L'))\n",
    "    new_img = np.array(new_img)\n",
    "    #draw a colored dot at the start point of the same color as colors[i]\n",
    "    for i,c in enumerate(coords1):\n",
    "        color = (int(colors[i][0]),int(colors[i][1]),int(colors[i][2]))\n",
    "        cv2.drawMarker(new_img,c,color,markerType=cv2.MARKER_CROSS,markerSize=20,thickness=10)\n",
    "\n",
    "    return new_img\n",
    "\n",
    "def visualize_matches(pix_coords, feats1, feats2, rgb1, rgb2, include_distance_maps = False):\n",
    "    matches,distance_maps = get_matches(feats1, feats2, pix_coords)\n",
    "    coords_norm1 = [((p[0]+0.5)/feats1.shape[0],(p[1]+0.5)/feats1.shape[1]) for p in pix_coords]\n",
    "    coords_norm2 = [((p[0]+0.5)/feats2.shape[0],(p[1]+0.5)/feats2.shape[1]) for p in matches]\n",
    "    return plot_matches(rgb1, rgb2, coords_norm1, coords_norm2, distance_maps if include_distance_maps else [])\n",
    "    # return plot_distribution(rgb1, rgb2, coords_norm1, distance_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell takes the click points from the above cell and visualizes matches/heatmaps in the provided video\n",
    "'''\n",
    "gif_frames = []\n",
    "pix_coords = click_coords + []\n",
    "t_start = 3\n",
    "t_end = 6\n",
    "fps = 5\n",
    "for t in np.linspace(t_start,t_end,(t_end-t_start)*fps):\n",
    "    frame = get_vid_frame(motion_clip,t)\n",
    "    pil_image = ToTensor()(Image.fromarray(frame))\n",
    "    img_pca_feats = dino_loader.get_pca_feats(pil_image.unsqueeze(0)).cuda().squeeze()\n",
    "    img = visualize_matches(pix_coords, outputs[\"dino\"], img_pca_feats, outputs['rgb'], pil_image.permute(1,2,0))\n",
    "    gif_frames.append(img)\n",
    "# save with mediapy\n",
    "out_clip = mpy.ImageSequenceClip(gif_frames, fps=fps)\n",
    "out_clip.write_videofile(\"nerfgun_matches_7.mp4\", fps=fps)\n",
    "\n",
    "#visualize the histogram of the difference maps across all frames\n",
    "# fig,ax = plt.subplots(1,len(pix_coords),figsize=(20,5))\n",
    "# all_dists = [[] for _ in pix_coords]\n",
    "# for t in np.linspace(t_start,t_end,(t_end-t_start)*fps):\n",
    "#     frame = get_vid_frame(motion_clip,t)\n",
    "#     pil_image = ToTensor()(Image.fromarray(frame))\n",
    "#     img_pca_feats = dino_loader.get_pca_feats(pil_image.unsqueeze(0)).cuda().squeeze()\n",
    "#     matches,distance_maps = get_matches(outputs[\"dino\"], img_pca_feats, pix_coords)\n",
    "#     for i,d in enumerate(distance_maps):\n",
    "#         all_dists[i].append(d.cpu().numpy().flatten())\n",
    "# for i,d in enumerate(all_dists):\n",
    "#     data = np.concatenate(d)\n",
    "#     ax[i].hist(data,bins=200)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
